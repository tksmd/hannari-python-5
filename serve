#!/usr/bin/env python

from pathlib import Path
import pickle
from io import StringIO

from bottle import route, run, abort, request, response
import pandas as pd


class ScoringService:
    model = None

    @classmethod
    def initialize(cls, base_path):
        if cls.model is None:
            model_path = Path(base_path).joinpath('model', 'decision-tree-model.pkl')
            with model_path.open(mode='rb') as f:
                cls.model = pickle.load(f)

    @classmethod
    def predict(cls, input):
        return cls.model.predict(input)


@route('/ping')
def ping():
    healthy = ScoringService.model is not None
    if not healthy:
        abort(404, 'Model not found')
    return {}


@route('/invocations', method='POST')
def invocations():
    content_type = request.headers.get('Content-Type')
    if content_type != 'text/csv':
        abort(415, 'This predictor only supports CSV data')

    raw_data = request.body.read()
    str_data = StringIO(raw_data.decode('utf-8'))
    input_df = pd.read_csv(str_data, header=None)

    print('Invoked with {} records'.format(input_df.shape[0]))

    predictions = ScoringService.predict(input_df)
    out = StringIO()
    pd.DataFrame({'results': predictions}).to_csv(out, header=False, index=False)
    result = out.getvalue()
    response.content_type = 'text/csv'
    response.set_header('Content-Length', str(len(result)))
    return result


def start_server(base_path='/opt/ml'):
    print('Starting the inference server')
    ScoringService.initialize(base_path)
    run(host='0.0.0.0', server='gunicorn', port=8080, debug=True)


if __name__ == '__main__':
    # start_server('test_dir')
    start_server()
